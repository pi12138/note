# 爬虫

## 什么是爬虫

- 爬虫：就是抓取网页数据的程序

## 爬虫是如何抓取网页数据的

- 网页的三大特征
  1. 每个网页都有自己的**唯一的URL**（统一资源定位符）来进行定位。
  2. 网页都使用HTML 来描述页面信息。
  3. 网页都使用 HTTP/HTTPS 协议来传输HTML数据。

- 爬虫的设计思路
  1. 首先确定需要爬取的网页URL地址
  2. 通过 HTTP/HTTPS 协议来获取对应的HTML页面
  3. 提取HTML页面里有用的数据：
    a. 如果是需要的数据，就保存起来
    b. 如果是页面里的其他URL，那就继续执行第二步
    
## 为什么选择python做爬虫？

- 做爬虫的语言有很多种，PHP、Java、C/C++、Python。。。。
- 爬虫是工具性程序，对速度和效率要求较高。
- PHP，天生不是干这个的，而且对多线程，异步支持不够好， 并发处理能力很弱。
- Java、的网络爬虫生态圈很完善，是Python爬虫最大的对手。但是Java语言本身很笨重，代码量很大，重构成本很高，
  爬虫经常需要改变代码。
- C/C++ 运行效率和性能几乎最强，但是学习成本很高。
- Python 语法优美，开发效率高，支持的模块多，相关的HTTP请求模块多
  还有强大的 Scrapy ,以及成熟高效的 scrapy-radis 分布式策略

## 如何抓取HTML页面

- 如何抓取HTML页面
  - http请求处理：urllib，urllib2, requests
  - 处理后的请求可以模拟浏览器发送请求，获取服务器响应文件。

- 解析服务器响应的内容
  - re, xpath, BeautifulSoup4(bs4), jsonpath, pyquery
  - 使用某种描述性语言来给我们需要提取的数据定义一个匹配规则，符合这个规则的数据就会被匹配

- 如何采集动态html，验证码的处理
  - 通用的动态页面采集: Selenium + PhantomJS(无界面，可以模拟浏览器功能，单并不是一个图形化浏览器)
  - 机器图像识别，Tesseract（机器学习库，谷歌维护）
  - 复杂验证码可以手动输入，或者打码平台

- Scrapy框架
  - 高定制性、高性能（默认使用异步网络框架twisted），所以下载速度非常快
  - 提供了数据存储、数据下载、提取规则等组件。

- 分布式策略
  - scrapy-radis，在Scrapy的基础上添加了一套以Radis 数据库为核心的一套组件，
  - 让Scrapy框架支持分布式的功能，
  - 主要在Radis中做请求指纹去重，请求分配，数据临时存储
- 爬虫、反爬虫、反反爬虫，之间的斗争:
  - 爬虫做到最后，最麻烦的是反爬虫机制。
  - User-Agent、代理、验证码、动态数据加载、加密数据
  - 数据价值是否值得去费劲的做反爬虫
  - 机器成本 + 人力 > 数据价值， 就不进行爬取了，一般做到封IP就结束了
  - 爬虫和反爬虫之间的战争，最后一定是爬虫胜利！
  - 为什么？ 只要是真实用户可以浏览的网页数据，爬虫就一定可以爬下来。